#!/usr/bin/env python2

#	Clipodder, a small "cron-able" utility to download video/audio podcasts
#	
#	Copyright (C) 2011  Afterburn, cdepillabout 
#
#	This program is free software: you can redistribute it and/or modify
#	it under the terms of the GNU General Public License as published by
#	the Free Software Foundation, either version 3 of the License, or
#	(at your option) any later version.
#
#	This program is distributed in the hope that it will be useful,
#	but WITHOUT ANY WARRANTY; without even the implied warranty of
#	MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#	GNU General Public License for more details.
#
#	You should have received a copy of the GNU General Public License
#	along with this program.  If not, see <http://www.gnu.org/licenses/>.  

import os
import urllib2
import ConfigParser
import json

import pycurl
import feedparser


class auto_podder():
	
	def __init__(self):
		self.config_dict = {}
		self.config_dict["default_config_dir"] = os.path.expanduser("~/.clipodder")
		self.config_dict["default_config"] = "%s/%s" % (self.config_dict["default_config_dir"], "config")
		self.config = ConfigParser.ConfigParser()
	
		if self.validate():
			self.load_conf()
			self.init_curl()
			for item in self.config.items("urls"):
				#Split it up, so we can specify more arguments. 
				feed_args = str(item[1]).split(" ")
				feed_url = feed_args[0]
				
				self.deal_with_url(feed_url, feed_args)
	
	
	def load_conf(self):
		self.config.readfp(open(self.config_dict["default_config"]))
		self.config_dict["download_dir"] = self.config.get("options", "download_dir")
		self.config_dict["downloads_per_url"] = self.config.getint("options", "downloads_per_url")
		self.validate(self.config_dict["download_dir"], True)
	
	def validate(self, path=None, create=False):
		if path:
			if os.path.exists(path):
				return True
		
			elif create:
				os.mkdir(path)
				return True
				
			else:
				return False
		
		if os.path.isdir(self.config_dict["default_config_dir"]) == False:
			self.init_auto_podder()
		
		if os.path.exists(self.config_dict["default_config"]) == False:
			self.init_auto_podder()
		
		return True
	
		
	def init_auto_podder(self):
		try:
			if os.path.isdir(self.config_dict["default_config_dir"]) == False:
				os.mkdir(self.config_dict["default_config_dir"])
				print "Created default config directory (%s)" % (self.config_dict["default_config_dir"])
		
		except Exception, e:
			print "Error creating default config dir (%s)" % (self.config_dict["default_config_dir"])
			print "Reason: %s" % e
			exit(1)
		
		sections = ["options", "urls"]
		
		for s in sections:
			self.config.add_section(s)
	
		self.config.set("options", "download_dir", os.path.expanduser("%s/%s" % (self.config_dict["default_config_dir"], "downloads")))
		self.config.set("options", "downloads_per_url", "2")
		self.config.set("options", "#The name of the url (not the url itself) needs to be something unique, ie a number", "")
		self.config.set("urls", "1", "#url here")
		self.config.set("urls", "2", "#another url")
	
		if os.path.exists(self.config_dict["default_config"]) == False:
			try:
				with open(self.config_dict["default_config"], "w") as config_file:
					self.config.write(config_file)
					print "Wrote default config (%s)" % self.config_dict["default_config"]
					print "Make sure you add some podcasts"
		
			except Exception, e:
				print "Error creating default config (%s)" % self.config_dict["default_config"]
				print "Reason: %s" % e
	
		print "Done"
		exit()
	
	def init_curl(self):
		self.curl = pycurl.Curl()
		self.curl.setopt(pycurl.FOLLOWLOCATION, 1)
		self.curl.setopt(pycurl.MAXREDIRS, 5)
		self.curl.setopt(pycurl.CONNECTTIMEOUT, 10)
	
	
	def download_file(self, name, path, url):
		print("Downloading [%s]" % os.path.basename(path))
		
		with open(path, "wb") as download_file:
			self.curl.setopt(pycurl.URL, str(url))
			self.curl.setopt(pycurl.WRITEDATA, download_file) 
			self.curl.perform()
		
	
	def get_link(self, data, download_types):
		"""
		This gets the downloadable links from an entry in an RSS feed.
		- data is a list of entries for a feed parsed with feedparser
		(i.e. feedparser.parse(url)["entries"][0:10]).
		- download_types is a list of filetypes to download.  "audio"
		and "video" are treated as MIME types, while any other string
		is just treated as a file extension.

		This function returns a list of urls to be downloaded.
		"""
		# the list of links we return from this function
		links = []

		# These files will be downloaded based on mime type.
		# For now, this is only "video" or "audio".
		mime_types = []
		# These files will be downloaded based on file extension.
		# For example, this could be "pdf" or "html".
		file_types = []

		# (these probably need to be expanded...)
		video_extensions = ["avi", "flv", "mov", "mp4"]
		audio_extensions = ["mp3", "ogg", "wav", "m4a"]

		if download_types == []:
			mime_types = ["video", "audio"]
		else:
			for dtype in download_types:
				if dtype == "video":
					mime_types.append("video")
					file_types.extend(video_extensions)
				elif dtype == "audio":
					mime_types.append("audio")
					file_types.extend(audio_extensions)
				else:
					file_types.append(dtype)

		for stuff in data["links"]:

			# get the mime type
			try:
				type_f = stuff["type"].split("/")[0]
			except:
				type_f = None

			# get the file extension
			try:
				extension = stuff["href"].split(".")[-1]
			except:
				extension = None

			# add it if the mime type matches, or the extension matches
			if type_f in mime_types or extension in file_types:
				
				if len(extension) > 3:
					to_find = stuff["href"].split(".")[-1][0:3]
					true_url = stuff["href"][0:stuff["href"].find(to_find)+len(to_find)]
					links.append(true_url)
					
				else:
					links.append(stuff["href"])
				
			

		return links


	def handle_parsed(self, data, url, args):

		if "title" in data["feed"]:
			p_title = data["feed"]["title"]

		else:
			p_title = os.path.basename(url)

		print "Checking %s" % p_title

		if self.validate("%s/%s" % (self.config_dict["download_dir"],p_title), True):
			for entry in data["entries"][0:self.config_dict["downloads_per_url"]]:

				urls = self.get_link(entry, args[1:])
				
				#Check to see if anything needs to be downloaded
				if not urls:
					print("Skipping %s, nothing found..." % [stuff["href"] for stuff in entry["links"]])
					continue

				for url in urls:
					# this should never happen?
					if not url:
						print("ERROR! url not valid from %s" % p_title)
						continue

					file_name = os.path.basename(url)
					file_path = "%s/%s/%s" % (self.config_dict["download_dir"], p_title, file_name)

					#Check to see if the file exists, if not, download
					if self.validate(file_path) == False:
						self.download_file(p_title, file_path, url)




	def deal_with_url(self, url, args):
		if url == "#url here":
			print "Add some podcasts! (%s)" % self.config_dict["default_config"]
			exit()
		
		elif url:
			self.handle_parsed(feedparser.parse(url), url, args)
		
	
	
	
clipodder = auto_podder()
